{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QX9JSz5-PYo3OV5yQvTz5dxwKTfGWhuw",
      "authorship_tag": "ABX9TyPD6+mJFsrOMRyU8TK3A870",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VEDANTPARAB404/SY-SKILL/blob/main/LCA3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPEvmREp-yxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c454a2-a5be-40b3-9140-0c08732b378b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-5c64fd4022d1>:10: DtypeWarning: Columns (7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv(file1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file1 = '/content/drive/My Drive/archive (9)/reduced_data_1.csv'\n",
        "file2 = '/content/drive/My Drive/archive (9)/reduced_data_2.csv'\n",
        "file3 = '/content/drive/My Drive/archive (9)/reduced_data_3.csv'\n",
        "file4 = '/content/drive/My Drive/archive (9)/reduced_data_4.csv'\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv(file1)\n",
        "df2 = pd.read_csv(file2)\n",
        "df3 = pd.read_csv(file3)\n",
        "df4 = pd.read_csv(file4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_main=pd.concat([df1,df2,df3,df4])\n",
        "df_main.head()"
      ],
      "metadata": {
        "id": "pQWJ3GXzKocb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.isnull().sum()"
      ],
      "metadata": {
        "id": "F1CX6W9lNrbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.isna().sum()"
      ],
      "metadata": {
        "id": "dWBcLGPUOAAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "df_main.drop_duplicates(inplace=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YJNq-rNqOLSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_main.info()"
      ],
      "metadata": {
        "id": "PHKfEdyIkpnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Droping useless features to improve the accuracy"
      ],
      "metadata": {
        "id": "sTzrJR5xGncb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop=['pkSeqID','subcategory','category']\n",
        "df_main.drop(columns=drop, inplace=True, errors='ignore')\n",
        "\n",
        "print(\"New Columns: \")\n",
        "df_main.columns"
      ],
      "metadata": {
        "id": "GAXZHLlkGxm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding"
      ],
      "metadata": {
        "id": "BB8tjwlNlRyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoders = {}\n",
        "for column in df_main.select_dtypes(include=['object', 'category']).columns:\n",
        "    df_main[column] = df_main[column].astype(str)  # Ensure all values are strings\n",
        "    le = LabelEncoder()\n",
        "    df_main[column] = le.fit_transform(df_main[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "print(\"✅complete\")\n",
        "print(df_main.head())"
      ],
      "metadata": {
        "id": "uSm_hrbElQ14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "correlation_matrix = df_main.corr()\n",
        "\n",
        "plt.figure(figsize=(35, 35))  # Adjust figure size if needed\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w-gM3rVjstuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_counts = df_main['attack'].value_counts()\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
        "sns.countplot(x='attack', data=df_main, order=attack_counts.index)\n",
        "plt.title('Distribution of Attack Types')\n",
        "plt.xlabel('Attack Type')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels if needed\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w_H88vCerDp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Balancing**(to prevent bias)"
      ],
      "metadata": {
        "id": "UI7_pQB21EIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "\n",
        "target = \"attack\"\n",
        "\n",
        "# 1. Original X and y\n",
        "X = df_main.drop(target, axis=1)\n",
        "y = df_main[target]\n",
        "\n",
        "# 2. Train-test split FIRST (important!)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Balance the training set ONLY\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "grouped = [g for _, g in train_df.groupby(target)]\n",
        "balanced_train = [\n",
        "    resample(g, replace=True, n_samples=100000, random_state=42)  # or any target size\n",
        "    for g in grouped\n",
        "]\n",
        "balanced_train_df = pd.concat(balanced_train).sample(frac=1, random_state=42)\n",
        "\n",
        "# 4. Now separate X and y again\n",
        "X_train_bal = balanced_train_df.drop(target, axis=1)\n",
        "y_train_bal = balanced_train_df[target]\n",
        "\n",
        "\n",
        "print(\"Balanced Training Set Shape:\", X_train_bal.shape, y_train_bal.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "358ivuMq0sqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling"
      ],
      "metadata": {
        "id": "NutqLU-n4Frb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Use the balanced training set from your updated code\n",
        "X = X_train_bal\n",
        "y = y_train_bal\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# (Optional) Convert back to DataFrame for inspection\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(\"✅ Feature scaling done\")\n",
        "print(X_scaled_df.head())\n"
      ],
      "metadata": {
        "id": "fhSods1s4mDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "LDmvRiLo4ubI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Combine X_train_bal and y_train_bal temporarily for correlation\n",
        "temp_df = X_train_bal.copy()\n",
        "temp_df[\"attack\"] = y_train_bal\n",
        "\n",
        "# Plot correlation matrix\n",
        "plt.figure(figsize=(12, 8))\n",
        "corr = temp_df.corr()\n",
        "sns.heatmap(corr, cmap='coolwarm', annot=False, linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Pj9Z3Ird5Goe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count of each attack type\n",
        "attack_counts = balanced_train_df['attack'].value_counts()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(attack_counts, labels=attack_counts.index, autopct='%1.1f%%', startangle=140, colors=plt.cm.tab20.colors)\n",
        "plt.title('Distribution of Attack Types (Balanced Training Set)')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures pie is drawn as a circle\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N70KpMQOmmHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature** **Selection**"
      ],
      "metadata": {
        "id": "jupNtLV66gDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FILTER METHODS"
      ],
      "metadata": {
        "id": "fcLmo0-V8ays"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA\n",
        "\n",
        "from sklearn.feature_selection import f_classif, SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "target = \"attack\"\n",
        "\n",
        "# Step 1: Split original data\n",
        "X = df_main.drop(target, axis=1)\n",
        "y = df_main[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Balance training data only\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "grouped = [g for _, g in train_df.groupby(target)]\n",
        "balanced_train = [\n",
        "    resample(g, replace=True, n_samples=100000, random_state=42)\n",
        "    for g in grouped\n",
        "]\n",
        "balanced_train_df = pd.concat(balanced_train).sample(frac=1, random_state=42)\n",
        "\n",
        "X_train_bal = balanced_train_df.drop(target, axis=1)\n",
        "y_train_bal = balanced_train_df[target]\n",
        "\n",
        "# Step 3: Apply ANOVA on training set\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_train_selected = selector.fit_transform(X_train_bal, y_train_bal)\n",
        "\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "selected_features = X_train_bal.columns[selected_feature_indices]\n",
        "print(\"Selected features:\", list(selected_features))\n",
        "\n",
        "# Step 4: Transform test set with same features\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Step 5: Train model and evaluate\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_selected, y_train_bal)\n",
        "y_pred = model.predict(X_test_selected)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the model: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "UWbciECV6fve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chi2\n",
        "\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "# Assuming X_train_bal and y_train_bal are already defined from the previous code\n",
        "\n",
        "# Apply Chi2\n",
        "selector = SelectKBest(score_func=chi2, k=10)  # Select top 10 features\n",
        "X_train_selected = selector.fit_transform(X_train_bal, y_train_bal)\n",
        "\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "selected_features = X_train_bal.columns[selected_feature_indices]\n",
        "print(\"Selected features (Chi2):\", list(selected_features))\n",
        "\n",
        "# Transform the test set using the selected features\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Train a RandomForestClassifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_selected, y_train_bal)\n",
        "y_pred = model.predict(X_test_selected)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the model (Chi2): {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "YUkXx3AQ8AtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Correlation-based feature selection\n",
        "correlation_threshold = 0.7\n",
        "\n",
        "# Calculate the correlation matrix for the training data (X_train_bal)\n",
        "correlation_matrix = X_train_bal.corr()\n",
        "\n",
        "# Find highly correlated features\n",
        "correlated_features = set()\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i):\n",
        "        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:\n",
        "            colname = correlation_matrix.columns[i]\n",
        "            correlated_features.add(colname)\n",
        "\n",
        "# Get all features present in both training and test data\n",
        "all_features = list(set(X_train_bal.columns) & set(X_test.columns))\n",
        "\n",
        "# Remove correlated features from the list of all features\n",
        "selected_features = [feature for feature in all_features if feature not in correlated_features]\n",
        "\n",
        "# Use selected features for training and test data\n",
        "X_train_corr = X_train_bal[selected_features]\n",
        "X_test_corr = X_test[selected_features]\n",
        "\n",
        "# Train RandomForestClassifier with selected features\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train_corr, y_train_bal)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_corr = model.predict(X_test_corr)\n",
        "\n",
        "print(\"Selected Featues: \",selected_features)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_corr = accuracy_score(y_test, y_pred_corr)\n",
        "print(f\"Accuracy with Correlation-based feature selection: {accuracy_corr:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "eJ26kZ-o-fXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WRAPPER** **METHODS**"
      ],
      "metadata": {
        "id": "PSLfvd8S-2ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ffs wrapper to find the features and accuracy\n",
        "\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "\n",
        "# Sequential Feature Selection (SFS)\n",
        "sfs = SequentialFeatureSelector(RandomForestClassifier(random_state=42), n_features_to_select=10, direction='forward')\n",
        "X_train_sfs = sfs.fit_transform(X_train_bal, y_train_bal)\n",
        "\n",
        "selected_feature_indices_sfs = sfs.get_support(indices=True)\n",
        "selected_features_sfs = X_train_bal.columns[selected_feature_indices_sfs]\n",
        "print(\"Selected features (SFS):\", list(selected_features_sfs))\n",
        "\n",
        "# Transform the test set using the selected features\n",
        "X_test_sfs = X_test[selected_features_sfs]\n",
        "\n",
        "# Train a RandomForestClassifier with selected features\n",
        "model_sfs = RandomForestClassifier(random_state=42)\n",
        "model_sfs.fit(X_train_sfs, y_train_bal)\n",
        "y_pred_sfs = model_sfs.predict(X_test_sfs)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_sfs = accuracy_score(y_test, y_pred_sfs)\n",
        "print(f\"Accuracy of the model (SFS): {accuracy_sfs:.4f}\")\n",
        "\n",
        "\n",
        "# Sequential Feature Selection (SBS)\n",
        "sbs = SequentialFeatureSelector(RandomForestClassifier(random_state=42), n_features_to_select=10, direction='backward')\n",
        "X_train_sbs = sbs.fit_transform(X_train_bal, y_train_bal)\n",
        "\n",
        "selected_feature_indices_sbs = sbs.get_support(indices=True)\n",
        "selected_features_sbs = list(X_train_bal.columns[selected_feature_indices_sbs])\n",
        "\n",
        "print(\"Selected features (SBS):\", selected_features_sbs)\n",
        "\n",
        "# Transform the test data\n",
        "X_test_sbs = X_test[selected_features_sbs]\n",
        "\n",
        "# Train a model and evaluate\n",
        "model_sbs = RandomForestClassifier(random_state=42)\n",
        "model_sbs.fit(X_train_sbs, y_train_bal)\n",
        "y_pred_sbs = model_sbs.predict(X_test_sbs)\n",
        "accuracy_sbs = accuracy_score(y_test, y_pred_sbs)\n",
        "\n",
        "print(f\"Accuracy of the model (SBS): {accuracy_sbs:.4f}\")\n"
      ],
      "metadata": {
        "id": "12YFio9u-2Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "\n",
        "\n",
        "target = \"attack\"\n",
        "\n",
        "# 1. Original X and y\n",
        "X = df_main.drop(target, axis=1)\n",
        "y = df_main[target]\n",
        "\n",
        "# 2. Train-test split FIRST (important!)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Balance the training set ONLY\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "grouped = [g for _, g in train_df.groupby(target)]\n",
        "balanced_train = [\n",
        "    resample(g, replace=True, n_samples=100000, random_state=42)\n",
        "    for g in grouped\n",
        "]\n",
        "balanced_train_df = pd.concat(balanced_train).sample(frac=1, random_state=42)\n",
        "\n",
        "# 4. Now separate X and y again\n",
        "X_train_bal = balanced_train_df.drop(target, axis=1)\n",
        "y_train_bal = balanced_train_df[target]\n",
        "\n",
        "# 1. Pre-filter features using ANOVA (select top 20)\n",
        "pre_selector = SelectKBest(f_classif, k=20)\n",
        "X_train_prefiltered = pre_selector.fit_transform(X_train_bal, y_train_bal)\n",
        "X_test_prefiltered = pre_selector.transform(X_test)\n",
        "\n",
        "# 2. Initialize a simpler model (or reduce complexity of RandomForest)\n",
        "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# 3. Backward Feature Elimination with optimizations\n",
        "num_features = X_train_prefiltered.shape[1]  # Start with fewer features\n",
        "best_features = []\n",
        "best_accuracy = 0\n",
        "\n",
        "for i in range(num_features, 0, -2):  # Increase step size to 2 (or more)\n",
        "    selector = RFE(estimator=model, n_features_to_select=i, step=2, n_jobs=-1)  # Parallelize\n",
        "    selector = selector.fit(X_train_prefiltered, y_train_bal)\n",
        "    selected_features = X_train_bal.columns[pre_selector.get_support(indices=True)][selector.support_]\n",
        "\n",
        "    X_train_rfe = selector.transform(X_train_prefiltered)\n",
        "    X_test_rfe = selector.transform(X_test_prefiltered)\n",
        "\n",
        "    model_final = RandomForestClassifier(random_state=42) # Use your original model here if desired\n",
        "    model_final.fit(X_train_rfe, y_train_bal)\n",
        "    y_pred = model_final.predict(X_test_rfe)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_features = list(selected_features)\n",
        "\n",
        "    print(f\"Number of features: {i}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nBest Number of Features: {len(best_features)}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"Best Features: {best_features}\")"
      ],
      "metadata": {
        "id": "Ffo50Gubk1qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EMBEDDED"
      ],
      "metadata": {
        "id": "Tnhc1LgQpGSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Embedded Method Example (L1 Regularization with Logistic Regression)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Use the selected features from previous steps (e.g., ANOVA)\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Initialize and train the model with L1 penalty\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', random_state=42) # Use liblinear solver for L1\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_embedded = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_embedded = accuracy_score(y_test, y_pred_embedded)\n",
        "print(f\"Accuracy with Embedded Method (L1 Regularization): {accuracy_embedded}\")\n",
        "\n",
        "# You can experiment with other models that have built-in feature selection,\n",
        "# such as decision trees or support vector machines with L1 regularization.\n"
      ],
      "metadata": {
        "id": "ExcbD8snpF33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bagging**"
      ],
      "metadata": {
        "id": "K8uTlE_R9QEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bagging\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Assuming X_train_bal, y_train_bal, X_test, and y_test are defined from previous code\n",
        "\n",
        "# Initialize the base estimator (e.g., decision tree)\n",
        "base_estimator = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialize the BaggingClassifier\n",
        "bagging_model = BaggingClassifier(estimator=base_estimator, n_estimators=10, random_state=42)\n",
        "\n",
        "# Train the bagging model\n",
        "bagging_model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_bagging = bagging_model.predict(X_test)\n",
        "\n",
        "# Evaluate the bagging model\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "print(f\"Accuracy of the Bagging model: {accuracy_bagging:.4f}\")\n"
      ],
      "metadata": {
        "id": "txODDa2r9Owv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting"
      ],
      "metadata": {
        "id": "_Mz3NsPU9xyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#boosting\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Initialize the AdaBoostClassifier\n",
        "adaboost_model = AdaBoostClassifier(n_estimators=50, random_state=42)  # Adjust n_estimators as needed\n",
        "\n",
        "# Train the AdaBoost model\n",
        "adaboost_model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_adaboost = adaboost_model.predict(X_test)\n",
        "\n",
        "# Evaluate the AdaBoost model\n",
        "accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)\n",
        "print(f\"Accuracy of the AdaBoost model: {accuracy_adaboost:.4f}\")\n",
        "\n",
        "\n",
        "# Initialize the GradientBoostingClassifier\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)  # Adjust n_estimators as needed\n",
        "\n",
        "# Train the Gradient Boosting model\n",
        "gb_model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "print(f\"Accuracy of the Gradient Boosting model: {accuracy_gb:.4f}\")\n"
      ],
      "metadata": {
        "id": "0tudb3sU9xSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a graph for all the accuracy comparison of the feature selection weve done\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy scores (replace with your actual values)\n",
        "accuracy_scores = {\n",
        "    'ANOVA': 1,  # Replace with your ANOVA accuracy\n",
        "    'Chi2': 1,  # Replace with your Chi2 accuracy\n",
        "    'Correlation': 1,  # Replace with your correlation accuracy\n",
        "    'RFE': 1,  # Replace with your RFE accuracy\n",
        "    'Backward Elimination': 1.00,  # Replace with your Backward Elimination accuracy\n",
        "    'Embedded (L1)': 0.99,  # Replace with your Embedded method accuracy\n",
        "    'Bagging': 1,  # Replace with your Bagging accuracy\n",
        "    'AdaBoost': 0.985, # Replace with your AdaBoost accuracy\n",
        "    'GradientBoosting':0.99 #Replace with your Gradient Boosting accuracy\n",
        "}\n",
        "\n",
        "# Method names\n",
        "methods = list(accuracy_scores.keys())\n",
        "\n",
        "# Accuracy values\n",
        "scores = list(accuracy_scores.values())\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
        "plt.bar(methods, scores, color='red')\n",
        "plt.xlabel(\"Feature Selection Methods\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Comparison of Feature Selection Methods\")\n",
        "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()  # Adjust layout to prevent labels from overlapping\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nTRlfEKM-F73"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}